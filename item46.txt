ITEM 46: PREFER SIDE-EFFECT-FREE FUNCTIONS IN STREAMS

ha meg csak ismerkedunk a streamekkel, akkor nehez lehet raerezni. kifejezni a feladatot stream pipelinekent nem egyszeru. ha sikerul, a prg futni fog, de lehet h nem igazan lesz benefitje. a streamek nem csupan egy APIt jelentenek hanem egy paradigmat ami a functional prgozason alapul. ahhoz h a streamek altal nyujtott kifejezoerot, sebesseget es idonkenti parhuzamositasi lehetosegeket ki tudjuk haszn, a paradigmat uugy el kell sajatitanunk mint az APIt

stream paradigma legfontosabb resze h a problemat transformationok seqjekent strukturaljuk meg, ahol minden stage resultja "is as close as possible to a pure function of the result of the previous stage". pure function az amelynek a resultja csak az inputjatol fugg: nem fugg semmilyen mutable statetol es nem updatel semmilyen statet. azt h ezt elerjuk, bmely function objnak amelyet stream opernek (intermediate v terminal) adunk at, side-effectektol mentesnek kell lennie

neha lathatunk az alabbihoz hasonlo streams kodot. word freq tablat epit
Map<String, Long> freq = new HashMap<>();
try(Stream<String> words = new Scanner(file).tokens()) { words.forEach(word -> { freq.merge(word.toLowerCase(), 1L, Long::sum); })
mi ezzel a gond? vegulis haszn streameket, lambdakat, metodus refeket es kihozza a jo eredmenyt. de ez valojaban nem streams kod; hanem iterativ kod streams kodnak alcazva. nem benefitel semmit a streams APIbol, hosszabb, nehezebben olvashato es kevesbe maintainable mint az iterativ kod. a problema oka h mindent a terminal forEach() operben csinal, egy olyan lambdat haszn ami external statet (freq tablat) modifol. egy olyan forEach() oper ami semmi mast nem csinal mint "present the result of the computation performed by a stream" az code smell, csakugy mint olyan lambda ami statet modifol

hogy kellene akkor kineznie?
Map<String, Long> freq = new HashMap<>();
try(Stream<String> words = new Scanner(file).tokens()) { freq = words.collect(groupingBy(String::toLowerCase, counting()));
uazt csinalja mint az elozo, de megfeleloen haszn a streams APIt. akkor miert csinalna barki az elozo modon? mert ismeros dolgokat haszn: forEach() hasonlo a for-each loopokhoz. de a forEach() oper az egyik legkevesbe powerful terminal oper, es a legkevesbe stream-friendly. expl iterativ, es ezert nem alkalmas parallelizationre. forEach() opert csak egy stream computation resultjanak reportolasara szabad haszn, a vegrehajtasara nem. neha van ertelme vmi mas celra is haszn, mint pl. hozzaadni egy stream computation resultjait egy preexisting collhoz

a javitott kod egy collectort haszn; ezt a conceptet meg kell tanulni a streamek hasznalatahoz. Collectors API felelmetesnek tunhet: 39 metodus van benne, es nemelyeknek akar 5 type paramja is lehet. jo hir h anelkul is jol tudjuk haszn h a reszletekbe nagyon bele kellene menni. kezdok ignoralhatjak a Collector ifacet es gondolhatnak egy collectorra ugy mint egy opaque obj amely encaps egy reduction strategyt. ebben a ctxben a reduction azt jelenti h egy stream elementjeit egy single objba kombinaljuk. a collector altal krealt obj alt egy coll (ezert hivjak collectornak)

a stream elementjeit Collectionba gyujto collectorok straightfwdok: toList(), toSet() es toCollection(collectionFactory); setet, listet ill. a prgozo altal spec coll typeot returnolnek. ennek ismereteben tudunk stream pipelinet irni amely top-ten listat extractol a freq tablankbol
List<String> topTen = freq.keySet().stream().sorted(comparing(freq::get).reversed()).limit(10).collect(toList());
vegyuk eszre h nem qualifyoltuk a toList()-et a classaval, Collectors-al. alt erdemes a Collectors memberjeit static imporotolni mivel olvashatobba teszik a stream pipelineokat

az egyetlen trukkos resz a comparator amit a sorted()-nek adunk at: comparing(freq::get).reversed(). a comparing() metodus egy comparator konstr metodus (item 14) ami egy key extraction functiont vesz at. "The function takes a word" (?), az "extraction" pedig egy table lookup: a bound metodus ref freq::get lookupolja a wordot a freq tablaban es returnoli h hanyszor fordul elo. vegul meghivjuk a reversed()-et a comparatoron, tehat a csokkeno gyakorisag szerint rendezzuk a wordoket. vegul 10 wordre limiteljuk a streamet es ezeket listbe collectoljuk

az elozo kodok a Scanner tokens() metodusat haszn h streamet krealjanak a scanneren. ez Java 9 metodus, korabbi releaseben a scannert, ami Iteratort impl, az item 47 szereplo adapterhez hasonlo modon tudjuk streamme alakitani (streamOf(Iterable<E>))

mi van a Collectors tobbi 36 metodusaval? legtobb azert van h streameket mapekbe tudjunk collectalni, ami sokkal nehezebb mint valodi collokba collectalni oket. minden stream elementhez egy key ES es value tart, es tobb stream element is tartozhat uahhoz a keyhez

legegyszerubb map collector a toMap(keyMapper, valueMapper) ami ket functiont vesz at; az egyik stream elementet egy keyre mappeli, a masik egy valuera. ezt a collectort haszn item 34 fromString() impl, ami egy mapet kreal ami az enum string formajabol magaba az enumba mappel
private static final Map<String, Operation> stringToEnum = Stream.of(values()).collect(toMap(Object::toString, e->e));
a toMap() ezen egyszeru formaja tokeletes ha a stream minden elementje egy unique keyre mappelodik. ha tobb stream element is uarra a keyre mappelodik, akkor a pipeline IllegalStateExceptionnal terminalodik

a toMap() komplikaltabb formai, csakugy mint a groupingBy() metodus, kulonbozo modokon kezelik az ilyen collisionoket. az egyik mod ha a toMap()-nak atadunk egy merge functiont is a key es value mapperek mellett. a merge function egy BinaryOperator<V>, ahol V a map value typeja. az uahhoz a keyhez kapcs tovabbi valuek a merge functiont haszn ossze lesznek kombinalva az existing valueval; pl. ha a merge function szorzas, akkor a vegso value a keyhez tartozo osszes value szorzata lesz

toMap() haromargos formaja szinten hasznos ha olyan "from a key to a chosen element associated with that key". pl. albumok streamje, es olyan mapet akarunk krealni ami az eloadorol a best-seller albumara mappel
Map<Artist, Album> topHits = albums.collect(toMap(Album::artist, a->a, maxBy(comparing(Album::sales))));
vegyuk eszre h a comparator a static maxBy() factory metodust haszn, ami static import a BinaryOperator-bol. ez a metodus egy Comparator<T> konvertal egy BinaryOperator<T>-be ami az adott comparator altal jelentett maxot szamitja ki. itt a comparatort a comparing() comparator konst metodus adja vissza, ami az Album::sales key extractor functiont veszi at. ez a map egy kicsit zavarosnak tunhet, de a kod jol olvashato. lenyegeben azt mondja: "konvertald az albumok stremjet egy mapbe, atmappelve minden eloadot a sales szerinti legjobb albumaba", ami gyak megegyezik a problema megfogalmazasaval

toMap() haromargos formajanak masik hasznalata egy olyan collector krealasa, ami collisionok eseten "utolso-write-gyoz" policyt valosit meg. sok streamnel az eredmeny nondeterministic lesz, de ha minden value identikus ami a mapping functionok szerint egy keyhez kapcs, v ha "they are all acceptable" akkor az alabbi collector pont jo lehet: toMap(keyMapper, valueMapper, (v1,v2) -> v2);

a toMap() van egy negyargos verzioja is, ami egy map factory, amit akkor haszn ha egy bizonyos map implt akarunk megadni, pl. EnumMap v TreeMap

toMap() verzioinak vannak variantjai toConcurrentMap() neven, amelyek jol futnak parallel, es ConcurrentHashMap instanceokat krealnak

toMap() metodus mellett a Collectors API nyujtja a groupingBy() metodust is, ami olyan collectorokat returnol amelyek egy classifier function alapjan kreal mapeket, amelyek elementeket groupolnak categorykba. a classifier function egy elementet vesz at es azt a categoryt returnoli, amelybe ez az element tart. a category az elementnek a map keyekent szolgal. a groupingBy() legegyszerubb valtozata csak egy classifiert vesz at, es egy olyan mapet returnol amelynek a valuejai az egyes categorykban levo elementek listjei. ez az a collector amit az item 45 Anagram prgban haszn, h olyan mapet krealjunk amely alphabetized wordbol az azonos alphabetizalasu wordok listajaba mappel: words.collect(groupingBy(word->alphabetize(word)))

ha azt akarjuk h a groupingBy() egy olyan collectort returnoljon amely egy olyan mapet kreal amelynek a valuejai nem listek, akkor megadhatunk egy downstream collectort is. a downstream collector "produces a value from a stream containing all the elements in a category". a legegyszerubb ha toSet()-et adunk at, ami egy olyan mapet eredmenyez, amelynek valuejai elementek setjei es nem listjei

atadhatunk toCollection(collectionFactory)-t is, amivel megkrealhatjuk a collokat amelyekbe az egyes categorykba tart elemek kerulnek. ily modon bmilyen coll typeot tudunk haszn. a groupingBy() ketargos valtozatanak masik egyszeru haszn, ha counting()-ot adunk at downstream collectorkent. ez egy olyan mapet eredmenyez, amely minden categoryt az obele tart elementek szamaval kapcs ossze, nem pedig az elementeket tart collal. ezt lattuk a freq tabla peldaban
Map<String,Long> freq = words.collect(groupingBy(String::toLowerCase, counting()));

groupingBy() harmadik valtozataban megadhatunk egy map factoryt is. vegyuk eszre h ez a metodus violalja a standard telescping arglist patternt: a mapFactory param a downStream param elott es nem utan van. ezzel nemcsak a containing collokat hanem a containing mapet is kontrollalni tudjuk: pl. megadhatunk egy olyan collectort ami egy olyan TreeMapet returnol amelynek valuejai TreeSetek

a groupingByConcurrent() metodus a groupingBy() mindharom overloadingjanak variantjait nyujtja. ezek a variantok hatekonyan futnak parallel es ConcurrentHashMap instanceokat krealnak. groupingBy() egy ritkan haszn rokona a partitioningBy(). ez classifier metodus helyett egy predicatet vesz at es egy olyan mapet returnol aminek a keye Boolean. ennek ket overloadja van, a masik a predicate mellett egy downstream collectort is atvesz

a counting() metodus altal returnolt collectorokat csak downstream collectorkent lehet haszn. uez elerheto kzvtl a Stremben is, a count() metodus reven, tehat sosincs ok arra h collect(counting())-ot hivjunk. van 15 tovabbi hasonlo Collectors metodus. ezek kozul 9 neve suming,averaging v summarizing (ezek a megfelelo primitiv stream typeokon muk). ide tart tovabba a reducing() metodus overloadjai es a filtering(), mapping(), flatMapping() es collectingAndThen() metodusok. a legtobb prgozo ezeket nyugodtan ignoralhatja. design szempontbol ezek a collectorok megprobaljak "partially duplicate the functionality of streams in collectors", h a downstream collectorok "ministream"-kent tudjanak muk

van meg 3 Collectors metodus amit meg kell emliteni. bar a Collectorsban vannak, nem tart collokat. minBy()/maxBy() egy comparatort vesznek at es a stream ez altal meghat min/max elementjet returnolik. a Stream iface min()/max() metodusainak altalanositasai, es BinaryOperator az azonos nevu metodusai altal returnolt binary operatorok analogiai. emlekezzunk vissza h a bestseller-album peldaban BinaryOperator.maxBy() metodust haszn

az utolso Collectors metodus a joining() amely csak CharSequence instanceokbol allo streameken muk, pl. stringeken. param nelkuli formajaban olyan collectort returnol, ami csak concatolja az elementeket. egyargos formaja egy egyszeru CharSequence paramot vesz at, aminek a neve delimiter es egy olyan collectort returnol ami joinolja a stream elementeket, a szomszed elementek koze beszurva a delimitert. ha delimiterkent vesszot adunk be, akkor a collector egy comma-separated values stringet returnol (de figyeljunk h a string ambiguous lehet ha a stream elementek vmelyike vesszo(ke)t tart). a haromargos forma a delimiteren kivul prefixet es suffixet is atvesz. a returnolt collector olyan stringeket kreal mint amiket collok kiprintelesekor kapunk, pl. [came, saw, conquered]

summary: a stream pipelineok prgozasanak lenyege a side-effectektol mentes function objk. ez von a streameknek es kapcs objknak atadott function objkra. a forEach() terminal opert csak a stream altal vegrehajtott computation eredmenyenek reportolasara haszn, a vegrehajtasara nem. a streamek megfelelo haszn erdekeben tudjunk a collectorokrol. a legfontosabb collector factoryk a toList(), toSet(), toMap(), groupingBy() es joining()