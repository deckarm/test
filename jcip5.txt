Java Concurrency in Practice

[Chapter 5. Building Blocks]

[[5.1. SYNCHRONIZED COLLECTIONS]]
Vector, Hashtable, Collections.synchronizedXXX factory matehodokkal krealt sync wrapper classok. encapsoljak a statejuket es syncelik minden public metodusukat

[[[5.1.1. Problems with Synchronized Collections]]]
threadsafek, de neha additional client-side locking is kell a compound actionokhoz (iteration, navigation (find next element), cond oper (pl. put-if-absent)); ha mas threadek conc modif a collt akkor vigyazni kell
Object getLast(Vector list) { int lastIndex = list.size()-1; return list.get(lastIndex);
void deleteLast(Vector list) { int lastIndex = list.size()-1; list.remove(lastIndex);
nem corruptaljak a vectort, akarhany thread hivja oket egyidejuleg; de ha az egyik thread size=10-et lat tehat get(9)-et hivna ra de meg azelott belep egy masik thread, ami szinten meg size=10-et lat, majd mond egy remove(9)-et, akkor utana az elso thread get(9)-je ArrayIndexOutOfBoundsException. ez a vektor specnek megfelel (non-existent element gettelese exception) de a hivo nem ezt varna a getLast()-tol
getLast() es deleteLast() bodyjat synchronized(list)-el guardolva tudjuk atomicka tenni

size() es get() kozti meretvaltozas lehetosege iteration soran is fennallhat; 
for(int i = 0; i < vector.size(); i++) doSomething(vector.get(i));
ha az egyik thread pont akkor torol elemet mikozben a masik iteral, ArrayIndexOutOfBoundsException. ez megint megfelel a vector specnek, de undesirable
synchronized(vector)-al korbeveve az iteralast megoldja; de ez nem csak azt preventalja h mas threadek modifyoljak a vectort ezalatt hanem azt is h accessaljak

[[[5.1.2. Iterators and Concurrentmodificationexception]]]
sync collok altal returnolt iteratorok nem oldjak meg a conc modifot, es failfastek: ha azt latjak h a coll valtozott az iter kezdete ota akkor unchecked ConcurrentModificationException-t dobnak. modif countot checkelnek es ha ez az iter soran valt akkor a hasNext()/next() eldobja az exct. de ez a check sync nelkul tortenik (perf okok miatt) tehat lehet h stale valuet latnak a modif countban es nem veszik eszre h modif tortent. exc lehet single threaded envben is; ha direktben removolunk objkat a collbol es nem az Iterator.remove()-al

List<Widget> widgetList = Collections.synchronizedList(new ArrayList<Widget>()); for(Widget w:widgetList) doSomething(w);
javac foreachbol is iterator/hasnext/next kodot gen; az exc ugy preventalhato ha az iter soran lockoljuk a collt. de ez igy nem engedi h mas threadek ezalatt _accessaljak_ a collt; vmint a doSomething() hivasa soran deadlock is fellephet (ld 10); hosszu ideig tarto lockolas scalability--, lock contention (ld 11) lehet
mo-kent le lehet cloneozni a collt es a copyn iteralni. a clone thread-confined, mas thread nem modifolhatja az iter soran, tehat nem lehet exc. maganak a cloneozasnak a soran lockolni kell a collt ami perf--, requirementtol fugg h belefer-e

[[[5.1.3. Hidden Iterators]]]
class HiddenIterator { 
  private final Set<Integer> set = new HashSet<>();
  public sync void add(Integer i);
  public sync void remove(Integer i);
  public void addTenThings() { for(int i = 0; i < 10; i++) { add(random.nextInt();} sout("added ten elements to" + set);
ez a sout egy hidden iteralas, mert a string concat StringBuilder.append(Object)-et eredmenyez, ami a coll toString()-jet hivja, ami pedig iteral a collon es minden elemre meghivja a toString()-et. ebbol igy lehet ConcurrentModificationException; acqolni kellene a HiddenIterator lockjat a set soutolasa elott. ha a HashSet be lenne wrappelve egy SynchronizedSet-be az encapsolna a syncet es nem lenne gond
coll hashCode()/equals() hasznalata soran is hidden iter (pl. ha a coll egy masik coll elementjekent vagy keyekent van haszn). containsAll()/removeAll()/retainAll(), collt atvevo konstruktorok eseten szinten; ezeknel mind fellephet ConcurrentModificationException

[[5.2. CONCURRENT COLLECTIONS]]
sync collok threadsafetyt ugy erik el h a coll statejehez minden accesst serializalnak. gyenge conc, throughput-- ha sok thread akarja accessalni
erre vannak a conc collok: ConcurrentHashMap (sync hashmap implk helyett), CopyOnWriteArrayList (sync list implk helyett, ahol foleg traversalas van). scalability++
Queue implk: ConcurrentLinkedQueue (FIFO), PriorityQueue (nem conc). operek nem blokkolnak ha a queue ures, hanem null returnolodik
BlockingQueue extends Queue: blocking insert/retrieve. producer-consumerhez nagyon jo (ld 5.3)
ConcurrentSkipListMap/Set: sync SortedMap/Set (pl. bewrappelt TreeMap/Set) conc replacementjei

[[[5.2.1. ConcurrentHashMap]]]
sync collok lockot tartanak az teljes oper soran; hosszu muveleteknel mas thread ezalatt nem tudja accessalni a collt
ConcurrentHashMap hash alapu, de masfele lockinggal, ami conc/scal++. nem kozos lockra synceli az osszes metodust hanem un lock striping (ld.11.4.3). tetszoleges szamu thread olvashatja conc, limitalt szamu thread irhatja conc, olvasas es iras tortenhet conc. conc envben throughput++, cserebe single threaded accessnel kicsi perf--
iterjei nem dobnak ConcurrentModificationExceptiont, tehat nem kell az iter soran lockolni a collt. ezek az iterek nem failfastek hanem weakly consistentek: lehetove teszik conc modifot, az iter krealasakori sorrendben traversalnak, tukrozHETik az iter krealas utan tortent coll modifokat
tradeoff: az egesz mapen operalo metodusok, pl. size()/isEmpty() eredmenyei csak estimatek; de conc envben ezek az ertekek egyebkent is moving targetek. ennek reven lett lehetseges perf++ a fontosabb operekre (get, put, remove, containsKey)
nem tudja exclusive accessre lockolni a mapet (vs sync map implk), de ez is reasonable tradeoff, mert a conc collok contentje varhatoan folyamatosan valtozik

[[[5.2.2. Additional Atomic Map Operations]]]
mivel ConcurrentHashMap nem lockolhato exclusive accessre, uj atomic operek krealasara nem hasznalhato client-side locking (mint amilyen 4.4.1 vector + putifabsent volt). helyette common compound operek (putifabsent, removeifequal) vannak atomickent impl a ConcurrentMap ifaceben

[[[5.2.3. CopyOnWriteArrayList]]]
sync List conc replacementje; jobb conc, es iterhez nem kell lockolni/copyzni a collt
threadsafetyje abbol szarm, h ha eff immut obj megfeleloen van publisholva, akkor az accessalasahoz nem kell tovabbi sync. mutabilityt ugy impl h minden modifnal kreal es republishol egy copyt a collbol. az iteratorjai refet tartanak a backing arrayre az iter kezdetekori allapotban; tobb thread iterelhet a collon anelkul h zavarnak egymast; az iteratorok nem dobnak ConcurrentModificationExceptiont es mindig az iter krealaskori allapotnak megfeleloen adjak vissza az elemeket, a kesobbi modifoktol fgtl
backing array lemasolasanak van ktge; copy-on-write collt akkor erdemes hasznalni ha iter gyakoribbb mint modif (pl. event notif systemek: notif deliverykor iteralni kell a beregisztralt listenereken; es ez sokkal gyakoribb mint maga a listener register/unregister)

[[5.3. BLOCKING QUEUES AND THE PRODUCER-CONSUMER PATTERN]]
blocking put/take metodusok. queue lehet bounded/unbounded, utobbinal put nem blokkol
producer-consumer: elvalasztja a work azonositasat az executiontol; todo listara teszi oket kesobbi processalasra. impl decoupling, jol haszn ha a p/c kulonbozo sebesseguek. a todo lista lehet pl. queue. pknek/cknek semmit nem kell tudniuk egymasrol. tip pl. threadpool + work queue (ld. Executor 6,8)
IRL pl: mosogato dish rackkel. p/c cimkek relativek, egy c egy masik folyamatban p lehet, pl. aki a megszaritott edenyt tovabbadja vhova elrakasra
BlockingQueue take jo a consumereknek, mert blokkol amig nincs data. ez neha OK (pl. servert eppen nem akarja client haszn), neha azt jelzi h a p/c ration hangolni kellene (pl. web crawler ahol az elvegzendo munka eff vegtelen)
ha p folyamatosan gyorsabban generalja a munkat mint ahogy a c fogyaszt akkor vegul out of mem lesz. mo blocking put + bounded queue; igy a c fel tud zarkozni
offer: return fail ha az itemet nem lehet berakni a queueba; overload scenariok hangolasara jo
p/c impl decouplolva, de a behav indirekte couplolva marad a shared queuen keresztul; design soran figyelni h milyen adatszerkezet felel meg a celnak legjobban, BQ helyett lehet h jobb pl semaphore (ld 5.5.3)
BQ implk: 
- LinkedBlockingQueue/ArrayBlockingQueue: FIFO, jobb perf mint a sync Listek
- PriorityBlockingQueue: prio alapu (natural order v Comparator)
- SynchronousQueue: valojaban nem queue, nem tarolja a datat, hanem threadek egy listajat maintaineli akik elemet akarnak berakni/kivenni. ~mosogato ahol a megmosott edeny nem a dish rackre kerul, hanem rogton odaadjuk egy elerheto szaritonak. latency--. jo az is h p tudja h az atvett elem mar egy c-nel van es nem csak var vhol arra h felvegyek. mivel nincs storage, put/take blokkolnak ha nincs thread aki belepne a masik oldalon es kivenne/betenne az elemet. leginkabb akkor jo ha eleg c van h mindig legyen vki aki felveszi az elemeket

[[[5.3.1. Example: Desktop Search]]]
local driveokon docokat keres es indexeli oket. producer vegzi a keresest es queuera teszi az eredmenyeket, consumer leveszi oket onnan es vegzi az indexelest. attekinthetobb mintha monolithic lenne
mindket class impl Runnable, van egy final BQ fieldjuk amivel dolgoznak; a foprg mindkettonek atadja uazt a LinkedBQ instanceot, es elinditja a ket threadet
p/c perf++: conc futhatnak, ha pl. az egyik IO a masik CPU igenyes, akkor a parh futtatas throughputja jobb mintha seq lennenek

[[[5.3.2. Serial Thread Confinement]]]
BQ implkben eleg internal sync van h p threadbol safely lehessen publisholni az objkat a c threadbe
mutable objk p-tol c-nek valo atadasara serial thread conft hasznalnak: objt egy thread ownolja exclusively, de ez az ownership safe publ reven attransferalhato egy masik threadnekpl. 
pl. obj poolok ennek reven tudjak "kikolcsonozni" ki az objkat a requesting threadeknek
ownership transfernel bizt kell h csak egy thread vegye at az objt. BQ-val egyszeru, de lehet ConcurrentMap.remove()-al vagy AtomicReference.compareAndSet()-el is

[[[5.3.3. Deques and Work Stealing]]]
Deque extends Queue (BlockingDeque extends BlockingQueue). ketvegu queue, head es tail oldalon is lehet insert/remove. impl pl ArrayDeque, LinkedBlockingDeque
work stealing: minden c-nek sajat dequeja van, es ha egy c elfogyasztotta a sajatjat akkor lophat vki mas dequejanak tailjerol. sima p/c-hez kepest scal++ mert nem egy darab shared queuen dolgoznak
jo olyankor amikor c-k egyben p-k is; pl. web crawler (egy page feldolgozasa alt azt jelenti h ujabb pageket kell crawlolni), grafalgok (pl. heap markolas GC soran) ha egy worker uj work unitot azonosit, a sajat dequeja vegere teszi (v work sharing design eseten vki mas dequejanak vegere), ha a dequeja ures akkor vki mastol probal lopni, igy minden workernek van munkaja

[[5.4. BLOCKING AND INTERRUPTIBLE METHODS]]
threadek blokkolodhatnak IO-ra varva, lock acqra varva, Thread.sleep()-bol ebredesre varva, mas thread altal vegzett szamitasra varva (tehat vmilyen external event). blokkolt thread alt BLOCKED, WAITING, TIMED_WAITING statebe kerul, ha az external event megtortenik akkor kerul vissza RUNNABLE-be
BQ put()/take() checked InterruptedExceptiont dobhatnak: blocking metodusok, amelyek ha interruptolodnak akkor megprobaljak ido elott befejezni a blockingot
interrupt kooperativ mechanizmus: ha A thread interruptolja B threadet az nem force hanem request. az interrupt kezelesere nincs spec, de a legcelszerubb az activity cancelezese

ha a mi metodusunk egy InterruptedExceptiont dobo metodust hiv, akkor a mi metodusunk is blocking metodus lesz, es kezelnie kell az interruptiont. 1) tovabb propagaljuk a mi hivonknak (catch-do something-rethrow, vagy siman not catch) 2) ha nem dobhatjuk tovabb mert pl. a mi kodunk egy Runnableben van, akkor catchelnunk kell, majd restorolni az interrupted statust a current threaden valo interrupt() hivassal, h az interrupt latszodjon feljebb is a call stackban
public void run() { try { processTask(queue.take()); } catch(InterruptedException e) {Thread.currentThread().interrupt(); }
ez a ket mod alt eleg. ami nem jo: catch, majd nem csinalunk vele semmit, mert igy elvesz annak a nyoma h a thread interruptolodott; az egyetlen kivetel amikor a Threadet extendaljuk es ezaltal mi kontrollaljuk a call stack feljebbi reszeit is (ld 7)

[[5.5. SYNCHRONIZERS]]
BQk spec collok, mert nem csak obj containerek hanem p/c flow controllerek is
synchronizer: obj amely a statejevel koordinalja threadek control flowjat. BQ, semaphores, latches, barriers (sajat is lehet, ld. ch14)

[[[5.5.1. Latches]]]
threadek progresset tudja kesleltetni, amig el nem eri a terminal statejet. mintha kapu lenne: amig el nem eri a terminal statet addig zarva van es nem mehet at rajta thread, terminal stateben kinyilik es atengedi oket (es utana orokre nyitva marad) 
pl. 1) szamitas nem vegzodik el amig a hozza szukseges rsck nem initelodnek; binary latch jelzi h "R rsc initelodott" es az R-t igenylo activityknek meg kell varniuk ezt a latchet 2) service nem indul el amig azok a servicek nem indultak el amiken o dependal. minden servicenek sajat binary latchje; S service indulasahoz meg kell varni azon servicek latcheit amiken S dependal; S inditasakor elengedni a latchjet h az orajta dependalo servicek is haladhassanak 3) multiplayer game, arra varunk h minden jatekos keszen alljon; latch akkor eri el a terminal statejet ha mindenki ready

CountDownLatch: egy v tobb thread varhat eventek egy setjere. poz szamra initelt counter (eventek szama amikre varunk), countDown() dekrementalja ha megtortent egy event, await() varja h counter=0 legyen. await() blokkol amig counter 0 lesz, a waiting thread interruptolodik vagy a wait timeoutol
pl. starting gate init to 1, ending gate init to worker threadek szama. minden worker thread megvarja a starting gatet (senki nem kezd dolgozni amig mindenki kesz nincs az indulasra); mindegyikuk countdownolja az ending gatet, igy a master thread eff tud varni amig az utolso worker is vegzett, es merni az eltelt idot
long timeTasks(int nThreads, final Runnable task) throws InterruptedException {
  final CountDownLatch startGate = new CountDownlatch(1); final CountDownLatch endGate = new CountDownlatch(nThreads); 
  for(int i = 0; i < nThreads; i++) {
    Thread t = new Thread() { run() { try { startGate.await(); 
	                                        try { task.run(); } finally { endGate.countDown(); 
    t.start();
	startGate.countDown(); endGate.await();
jobb mintha krealas utan csak ugy elinditottuk volna threadeket; a start gate biztositja hogy egyik thread se indul tul koran, az ending gate pedig lehetove teszi a master szamara h az utolso megallo threadet figyelje, ne kelljen seq mindegyikre varnia 

[[[5.5.2. FutureTask]]]
szinten latchkent viselkedik. FutureTask altal repr szamitas Callableval van impl, lehetseges statejei: waiting to run, running, completed. completion modjai: normal, cancel, exc. ha FutureTask elerte a completed statet akkor orokre ott marad
Future.get() eredmenye a task allapotatol fugg. ha az completed akkor azonnal returnoli az eredmenyt, egyebkent blokkol amig a task completed nem lesz, es akkor returnol vagy dob exct. a FutureTask szallitja az eredmenyt a szamitast vegzo threadtol a retrievelo thread(ek)nek; specje garantalja a safe publisholast

executor fw async taskok reprjara haszn FutureTaskot; hasznalhato hosszu szamitasok reprjara is amik hamarabb elkezdhetok mint ahogy az eredmenyre szukseg van, ezaltal idot takaritva meg
class PreLoader {
  private final FutureTask<ProductInfo> future = new FutureTask<ProductInfo>(new Callable<ProductInfo>() {public ProductInfo call() {return loadProductInfo();}})
  private final Thread thread = new Thread(future);
  public void start() { thread.start(); }
  public ProductInfo get() throws InterruptedException { try { return future.get(); } catch(...)
a FutureTask irja le a ProductInfo DBbol valo betoltesenek taskjat, a threadben vegzodik a szamitas. start metodusban inditjuk a threadet, mert konstrban v static initializerben nem javasolt. amikor a prgnak kesobb szuksege lesz a ProductInfora akkor hivja a get()-et ami visszaadja a betoltott adatot vagy var a betoltes befejezodeseig
(exceptionkezelo utility metodus leirasa)

[[[5.5.3. Semaphores]]]
adott idoben egy rsct accessalo vagy egy actiont elvegzo activityk szamat tudja kontrollalni. pl. rsc poolok impljahoz, coll boundolasahoz
permitek setjet manageli, az init numbert a konstr kapja meg. az activityk acqolhatnak permitet es releaselhetik ha vegeztek. ha nincs szabad permit akkor az acq blokkol amig lesz (vagy amig nem lesz interrupt/timeout). a release visszaadja a permitet a semnek
binary sem: egy db permit. ez tulkepp mutex nonreentrant lockinggal, akinel van az egy darab permit aze a mutex
impl valojaban nem tartalmaz valo permit objkat, es a permitek nincsenek threadekkel osszerendelve, tehat az egyik threadbol acqolt permit releaselheto egy masik threadbol. acq tekintheto permit consumalasnak, release pedig krealasnak; a permitek szama nohet is az init ertekhez kepest (?)
pl. rsc (pl. DB conn) poolok: sem init a pool sizenak megfeleloen, rsc fetcheles elott permit acq (blokkol ha a pool ures, unblokkol ha ujra nem ures), rsc viszzatetel utan permit release (ld 12, bounded buffer class)
pl. coll boundolas
class BoundedHashSet<T> {
  private final Set<T> set; private final Semaphore sem;
  public BoundedHashSet(int bound) { this.set = Collections.synchronizedSet(new HashSet<T>()); sem = new Semaphore(bound);
  public boolean add(T o) throws InterruptedException { sem.acquire(); try { wasAdded = set.add(o); return wasAdded; } finally { if(!wasAdded) sem.release(); }
  public boolean remove(Object o) { boolean wasRemoved = set.remove(o); if(wasRemoved) sem.release(); return wasRemoved;
coll a kivant max sizera initelve. add() permitet acqol mielott elemet rakna a collba, ha nem kerult be akkor rogton releaseli. remove() releaseli a permitet. az underlying Set semmit nem tud a boundrol, azt teljesen a BoundedHashSet kezeli

[[[5.5.4. Barriers]]]
latchok egyszer hasznalatosak; ha elerik a terminal statet akkor nem resetelhetoek
barrierek szinten threadeket blokkolnak  amig vmi event be nem kov; kulonbseg h a latchek eventre varnak, a barrierek pedig mas threadekre. pl. "holnap 6-kor talalkozo a plazaban, ha odaertel, varj addig amig mindenki meg nem erkezik"

CyclicBarrier fix szamu resztvevo; parh iter algok lebontasa fix szamu alproblemara. Threadek await()-et hivnak amikor elerik a barrier pointot, await() blokkol amig minden thread oda nem ert. ha minden thread odaert (barrier passed) akkor az osszeset atengedjuk, a barrier resetelodik es ujra hasznalhato. ha az await() timeoutol vagy az egyik await()-ben blokkolt thread interruptolodik (barrier broken), akkor minden folyamatban levo await() hivas BrokenBarrierException. ha barrier passed akkor az await() minden threadnek egy unique arrival indexet returnol, amellyel vezetot valaszthatnak. konstr atvehet egy barrier actiont (Runnable) amit az egyik subtask thread akkor executol amikor a barrier mar passed, de meg mielott a blokkolt threadek releaselodnenek
haszn pl. szimulaciokhoz, ahol egy step reszei kiszamithatoak parh, de a teljes stepnek be kell fejezodni mielott a kov stepre lephetnenk (hosszu peldaprg)

Exchanger: ket party datat exchangel a barrier pointnal. hasznos ha a partyk asszim activityt vegeznek, pl. egyik tolti a buffert, a masik fogyasztja, es Exchanger segitsegevel cserelnek el egy tele buffert egy uresre. safe publt biztosit
exchange idozitese responsivity requirementtol fugghet. legegyszerubb tele/ures allapotnal; de lehet reszleges buffer toltottseg + idokorlat mellett is

[[5.6. BUILDING AN EFFICIENT, SCALABLE RESULT CACHE]]
cache: latency--, throughput++, cserebe kicsit tobb mem haszn
naiv cache: single-threadedben javit, de perf bottleneckbol scal bottlenecket csinal

interface Computable<A,V> { V compute(A arg) throws InterruptedException;
class ExpensiveFunction implements Computable<String, BigInteger> { public BigInteger compute(String arg) {...

class Memoizer1<A,V> implements Computable<A,V> {
  private final Map<A,V> cache = new HashMap<A,V>();
  private final Computable<A,V> c;
  public sync V compute(A arg) throws InterruptedException { V result = cache.get(arg); if(result == null) { result = c.compute(arg); cache.put(arg,result); } return result;
HashMap nem threadsafe, ezert az egesz compute() syncelve van; scal--, csak egy thread tudja execelni. ha olyan threadek kenyszerulnek varni amik nem mar becachelt valuekra varnak, akkor meg lassabb is lehet mint cacheles nelkul

Memoizer2 uez csak cache = new ConcurrentHashMap<A,V>(), es compute() nem sync. ezt igy tobb thread is tudja conc hasznalni, de ha ket thread egyszerre hivja compute()-ot, akkor uazt az erteket szamolhatjak ki; ez jobb esetben csak ineff, rosszabb esetben akar safety risk is lehet. valahogy tehat jeleznunk kellene ha egy bizonyos ertek computalasa eppen folyamatban van h ne kezdjen mas is hozza

FutureTask: szamitasi processt repr ami vagy completed vagy nem; FutureTask.get() azonnal returnoli az eredmenyt ha megvan, egyebkent blokkol amig a szamitasnak vege lesz
class Memoizer3<A,V> implements Computable<A,V> {
  private final Map<A,Future<V>> cache = new ConcurrentHashMap<A,Future<V>>();
  private final Computable<A,V> c;
  public V compute(A arg) throws InterruptedException {
    Future<V> f = cache.get(arg);
	if(f == null) { 
	  Callable<V> eval = new Callable<V>() { public V call() throws InterruptedException { return c.compute(arg);
	  FutureTask<V> ft = new FutureTask<V>(eval);
	  f = ft; cache.put(arg, ft); ft.run(); //c.compute() hivasa
	try { return f.get();
eloszor csekkeli h a szamitas elkezdodott-e mar (vs Memoizer2 ami azt nezi h befejezodott-e). ha nem akkor FutureTaskot kreal, regisztralja a mapbe es inditja a szamitast; ha igen akkor megvarja a futo szamitas eredmenyet
jo conc, ismert eredmenyt azonnal visszaadja, szamitas alatt levo eredmenyt a threadek megvarjak. problema h az if blokk nem atomic, es kisebb vggel de meg mindig elofordulhat h ket thread is elkezdi uannak az erteknek a szamitasat

mo atomic putIfAbsent() hasznalata
      f = cache.putIfAbsent(arg, ft); 
	  if(f == null) { f = ft; ft.run(); } 
	  try { return f.get(); } catch(CancellationException e) { cache.remove(arg, f);
ha nem egy erteket hanem egy Futuret cachelunk, az cache pollution lesz; ha a szamitas cancel/fail akkor az erre von tovabbi szamitasi kiserletek is cancel/fail lesznek; ezert ilyen esetben removoljuk a Futuret a cachebol
cache expirationnal/evictionnal(regi entryk eltavolitasa h ujaknak legyen hely) ez nem fogl

ezt a valtozatot mar felhasznalhatjuk pl. 2-beli factorizer servlethez
class Factorizer implements Servlet {
  private final Computable<BigInteger, BigInteger[]> c = new Computable<>() { public BigInteger[] compute(BigInteger arg) { return factor(arg);
  private final Computable<BigInteger, BigInteger[]> cache = new Memoizer<>(c);
  public void service() { try { encodeResp(cache.compute(reqNr)); } catch(InterruptedException e) {...
